{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento del texto, extraemos todo el texto del pdf y lo guardamos en un archivo de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracción completada. El texto se guardó en '../data/cooked\\texto_extraido.txt'.\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"  # Extrae texto de cada página\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Ruta de tu PDF\n",
    "pdf_path = \"../data/raw/leyes_ajedrez.pdf\"  # Cambia esto por la ubicación de tu archivo\n",
    "\n",
    "# Extraer texto\n",
    "texto_extraido = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Crear carpeta si no existe    \n",
    "output_dir = \"../data/cooked\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Guardar el texto en un archivo dentro de 'data/cooked'\n",
    "output_path = os.path.join(output_dir, \"texto_extraido.txt\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(texto_extraido)\n",
    "\n",
    "print(f\"✅ Extracción completada. El texto se guardó en '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La base de datos elegida, ha sido ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\almaz\\.conda\\envs\\prueba_rag_tailor\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\almaz\\.conda\\envs\\prueba_rag_tailor\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\almaz\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de la primera línea: [-4.75044623e-02  4.89124469e-02  1.27341738e-02  3.71110216e-02\n",
      " -6.25089034e-02  6.24664910e-02  1.16436899e-01  1.00796316e-02\n",
      "  4.63477075e-02  3.58318053e-02  2.38445606e-02  1.86951656e-03\n",
      " -4.92336135e-03  1.57713201e-02  3.41440667e-03 -7.20255524e-02\n",
      " -2.60634460e-02  6.74121603e-02 -6.22904599e-02  6.52326504e-03\n",
      "  6.79132789e-02 -2.33350545e-02 -4.56841663e-03  1.08755054e-02\n",
      " -9.58510786e-02 -3.89817655e-02  5.08660404e-03  1.80085637e-02\n",
      " -3.48556116e-02 -7.94901252e-02  8.54951441e-02 -6.16623648e-03\n",
      "  3.67506035e-02 -4.58656140e-02 -6.46752566e-02 -4.30934355e-02\n",
      "  5.96923865e-02 -3.52040194e-02  5.32939211e-02  5.61981611e-02\n",
      " -1.11851528e-01  6.75243279e-03 -9.78955925e-02 -4.36949432e-02\n",
      " -2.68482175e-02 -5.19135632e-02  5.89504763e-02 -4.86038029e-02\n",
      "  1.68348681e-02  5.84590202e-03 -3.57686505e-02 -6.13384880e-02\n",
      "  2.84125417e-04  3.52543741e-02  4.63330820e-02  8.03012308e-03\n",
      "  3.54612730e-02  2.48460993e-02  3.17950733e-02  1.13081478e-03\n",
      "  7.17853233e-02  5.04170842e-02 -1.16556026e-01  3.65999192e-02\n",
      " -6.35519475e-02 -9.78633836e-02  6.45354316e-02  1.71494707e-02\n",
      " -5.41512929e-02 -4.21260856e-02  4.94452268e-02 -6.59079105e-02\n",
      "  2.67171580e-03  6.23515099e-02 -3.87025066e-02  7.04011321e-02\n",
      " -3.15172076e-02 -2.13392396e-02  1.23620462e-02 -1.14138372e-01\n",
      "  1.27168810e-02 -8.50746930e-02 -6.88427985e-02  6.86556380e-03\n",
      " -1.08076520e-02  3.03841801e-03  3.45751818e-04  1.24612842e-02\n",
      "  1.23949960e-01  2.84584928e-02  1.90608520e-02  5.48701137e-02\n",
      " -9.04197767e-02 -2.25137938e-02  1.26951272e-02  9.02222097e-03\n",
      "  5.36161140e-02 -1.73600193e-03 -4.48196717e-02  1.41072497e-01\n",
      "  8.45330581e-02  7.69907832e-02  8.76096264e-02  4.99406457e-02\n",
      " -1.80542562e-02 -8.40341393e-03 -4.26705740e-03 -9.86802205e-03\n",
      " -1.98432151e-02 -8.45510699e-03 -3.76608372e-02 -4.75593954e-02\n",
      "  2.79836878e-02  4.40640040e-02 -8.06178432e-03 -1.00647397e-02\n",
      "  9.79274139e-02 -4.60561402e-02  2.40202639e-02 -8.18423182e-02\n",
      "  3.02797128e-02 -5.06592973e-04 -1.04215532e-03 -1.27741490e-02\n",
      "  3.44632007e-02  8.41966271e-03  2.43636519e-02  1.04492655e-34\n",
      " -5.90379648e-02 -5.43019734e-02 -5.07263318e-02  6.26770481e-02\n",
      " -2.61942279e-02  5.16749769e-02 -2.71590576e-02 -1.42998593e-02\n",
      " -2.56727589e-03 -2.41812766e-02 -8.02464224e-03 -5.47834039e-02\n",
      "  1.67864598e-02 -6.45117089e-02 -1.67489622e-03  6.93068728e-02\n",
      " -5.04355542e-02 -1.55576486e-02 -5.05594388e-02 -8.93459190e-03\n",
      " -8.62737447e-02  8.24768618e-02  2.17418633e-02  1.82894412e-02\n",
      " -1.67918280e-02 -3.01058963e-02  2.47153565e-02 -4.26301956e-02\n",
      " -3.55868079e-02  3.02434638e-02  8.23343322e-02  5.41530401e-02\n",
      " -8.20654817e-03  1.16411792e-02  4.53024246e-02  1.43058263e-02\n",
      "  3.51780802e-02 -6.04889281e-02  1.09419655e-02 -4.19548526e-02\n",
      "  8.49995911e-02 -5.08884061e-03  3.24804708e-02  8.60204101e-02\n",
      " -3.48674543e-02  4.12665680e-02 -8.20005015e-02  3.80382873e-02\n",
      "  4.65678573e-02  5.79270087e-02  2.63898894e-02 -3.69012691e-02\n",
      " -6.44682795e-02 -4.09634598e-02 -3.27477008e-02  7.70236477e-02\n",
      " -1.33114904e-01  9.05724149e-03  6.21876642e-02 -4.79019666e-03\n",
      "  2.19306704e-02  4.70192134e-02  1.82545092e-02  1.15371216e-02\n",
      " -7.80667760e-04 -1.06495835e-01 -2.42232322e-03 -6.01920597e-02\n",
      "  4.26694937e-02 -6.39910810e-03 -5.31026088e-02 -2.48081312e-02\n",
      " -1.91008560e-02  6.67137802e-02  2.36085127e-03 -1.87982712e-02\n",
      " -2.24481616e-02  3.30207013e-02 -2.27936376e-02 -7.85423722e-03\n",
      " -1.09523855e-01  2.90179942e-02  8.85900185e-02  5.16201667e-02\n",
      "  1.53374135e-01  5.90051301e-02 -3.01746242e-02 -6.06812537e-03\n",
      " -9.86765884e-03  6.16618656e-02  2.65663285e-02  6.90471008e-02\n",
      " -2.35266313e-02 -1.06831402e-01  6.11752272e-02 -1.72377890e-33\n",
      " -2.71595269e-02  5.12711518e-03  1.40519952e-02  4.29340675e-02\n",
      " -3.20915855e-03 -1.18167782e-02 -5.00749797e-02  6.01130687e-02\n",
      " -1.09027876e-02 -8.02550986e-02  1.41143482e-02 -8.87261629e-02\n",
      "  1.29110530e-01 -2.77687935e-03  4.90845218e-02 -5.04523404e-02\n",
      "  5.38769029e-02 -1.03869587e-01 -3.03189158e-02  7.62815103e-02\n",
      " -2.73440406e-02  4.23726737e-02  1.08678569e-03  9.24528316e-02\n",
      " -7.13028153e-03 -5.09118848e-02 -1.25383623e-02  3.78009342e-02\n",
      " -9.14406180e-02  2.79138004e-03  8.85461047e-02 -4.49561402e-02\n",
      " -5.31745236e-03 -4.67836820e-02 -7.23720640e-02 -2.53253151e-02\n",
      "  7.81800821e-02  8.76229722e-04  2.97068362e-03  6.50811940e-02\n",
      " -2.53386013e-02  4.03856896e-02 -4.27052863e-02  5.85143119e-02\n",
      " -1.13920914e-02  2.23690830e-02 -6.20608814e-02 -5.62109202e-02\n",
      "  1.93309002e-02 -8.06603301e-03 -1.43439230e-02 -4.79530543e-02\n",
      " -5.74387722e-02  1.39466142e-02  6.89928979e-02 -2.73771901e-02\n",
      "  1.02233114e-02 -4.88367453e-02 -3.18277515e-02  6.15159236e-03\n",
      "  5.53811491e-02  1.18792526e-01  2.79352516e-02 -3.58289331e-02\n",
      "  6.67685717e-02 -2.61917058e-02 -5.48359640e-02 -2.41903169e-03\n",
      "  5.28179444e-02 -9.48879030e-03  1.26872197e-01 -2.06693970e-02\n",
      " -8.98289979e-02 -7.98647292e-03 -9.30376630e-03  4.24564164e-03\n",
      " -3.72129194e-02  9.69351605e-02 -2.97396146e-02 -1.25339534e-02\n",
      "  5.51020093e-02  5.96129410e-02 -4.90164571e-02 -2.71599106e-02\n",
      "  3.41912508e-02 -3.06354389e-02 -9.38249752e-03  1.22948969e-02\n",
      " -7.43849669e-03 -1.02433585e-01  5.06000295e-02 -2.26445738e-02\n",
      "  6.73964294e-03 -1.88290309e-02  4.31936719e-02 -1.82645188e-08\n",
      " -4.60406803e-02  2.46969294e-02 -6.20786138e-02 -8.98316409e-03\n",
      "  4.22681347e-02 -5.46964211e-03 -4.14383858e-02  2.54661627e-02\n",
      "  1.31141264e-02  3.16578187e-02  5.56757785e-02  1.42275970e-02\n",
      " -1.03649748e-02  9.81195942e-02 -6.13885038e-02  6.10173717e-02\n",
      "  9.29333642e-03  7.90136978e-02 -3.38275358e-02  2.38476563e-02\n",
      "  3.21798623e-02 -2.91430913e-02 -6.56148791e-02 -1.42004760e-02\n",
      "  1.02662757e-01 -2.12192088e-02 -6.33278415e-02 -2.80831065e-02\n",
      "  8.49515013e-03 -7.36703500e-02  1.55479014e-02  2.53564212e-02\n",
      "  2.03757938e-02 -1.25167847e-01 -3.71653251e-02  2.82582808e-02\n",
      " -6.29359391e-03 -9.49872285e-03  4.25446816e-02 -3.32132205e-02\n",
      "  2.33318433e-02  2.10316051e-02  5.14743365e-02 -2.30306331e-02\n",
      " -1.79145131e-02 -8.70079845e-02 -3.33489515e-02 -3.28541128e-03\n",
      " -3.86269465e-02 -3.36989723e-02 -2.88533941e-02  1.46411196e-03\n",
      "  1.14315815e-01 -1.72386710e-02  5.45899197e-02 -9.60597396e-02\n",
      "  1.58994626e-02  4.22969796e-02 -1.13363393e-01  2.01256499e-02\n",
      "  9.12697539e-02  2.07919441e-02  4.11036536e-02 -9.20403749e-02]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Cargar el modelo preentrenado\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Puedes cambiar el modelo si lo deseas\n",
    "\n",
    "# Leer el archivo de texto\n",
    "with open('../data/cooked/texto_extraido.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Generar embeddings para cada línea del archivo\n",
    "embeddings = model.encode(lines, convert_to_numpy=True)\n",
    "\n",
    "# Ver el primer embedding para verificar\n",
    "print(\"Embedding de la primera línea:\", embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de vectores en el índice: 1827\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Dimensión de los embeddings (depende del modelo que uses, por ejemplo, 384 para 'all-MiniLM-L6-v2')\n",
    "dim = embeddings.shape[1]\n",
    "\n",
    "# Crear el índice FAISS (usamos IndexFlatL2 para distancia euclidiana)\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "# Agregar los embeddings al índice\n",
    "index.add(embeddings)\n",
    "\n",
    "# Verifica cuántos vectores se han añadido\n",
    "print(\"Número de vectores en el índice:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "consulta = [\"cuando se gana una partida\"]\n",
    "consulta_embedding = model.encode(consulta, convert_to_numpy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índices de los vectores más cercanos: [[483 760 937 655 370]]\n",
      "Distancias de los vectores más cercanos: [[0.5913608  0.5915155  0.595267   0.61422104 0.6148168 ]]\n"
     ]
    }
   ],
   "source": [
    "# Buscar los 5 vectores más cercanos\n",
    "k = 5\n",
    "distances, indices = index.search(consulta_embedding, k)\n",
    "\n",
    "print(\"Índices de los vectores más cercanos:\", indices)\n",
    "print(\"Distancias de los vectores más cercanos:\", distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el índice\n",
    "faiss.write_index(index, \"mi_indice.index\")\n",
    "\n",
    "# Cargar el índice desde el archivo\n",
    "index_cargado = faiss.read_index(\"mi_indice.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han agregado 1827 embeddings al índice.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# Número de dimensiones de los embeddings (debería coincidir con la salida de tu modelo)\n",
    "dim = embeddings.shape[1]\n",
    "\n",
    "# Crear el índice FAISS (puedes elegir el tipo de índice dependiendo de tus necesidades)\n",
    "index = faiss.IndexFlatL2(dim)  # IndexFlatL2 es para distancias L2\n",
    "\n",
    "# Agregar los embeddings al índice\n",
    "index.add(embeddings)  # embeddings es un array numpy de tamaño (número de textos, dimensiones del embedding)\n",
    "print(f\"Se han agregado {embeddings.shape[0]} embeddings al índice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento recuperado: Sin embargo, la partida es tablas si la posición es tal que el oponente no puede dar \n",
      "\n",
      "Distancia: 0.4856340289115906\n",
      "Documento recuperado: la consideración de una oferta de tablas. \n",
      "\n",
      "Distancia: 0.5014404058456421\n",
      "Documento recuperado: La partida es tablas cuando se alcanza una posición en la que ningún jugador puede \n",
      "\n",
      "Distancia: 0.5126779079437256\n",
      "Documento recuperado: Si la posición es tal que ninguno de los jugadores puede dar mate, la partida es tablas. (Ver \n",
      "\n",
      "Distancia: 0.5383651852607727\n",
      "Documento recuperado: embargo, decretará tablas si la posición es tal que el oponente no puede dar jaque \n",
      "\n",
      "Distancia: 0.5409550070762634\n"
     ]
    }
   ],
   "source": [
    "# Función para realizar la búsqueda en FAISS\n",
    "def buscar_similaridad(query, k=5):\n",
    "    # Generar el embedding para la consulta\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    \n",
    "    # Realizar la búsqueda en FAISS\n",
    "    D, I = index.search(query_embedding, k)  # D es la distancia, I los índices\n",
    "    \n",
    "    # Mostrar los resultados\n",
    "    for i in range(k):\n",
    "        print(f\"Documento recuperado: {lines[I[0][i]]}\\nDistancia: {D[0][i]}\")\n",
    "\n",
    "# Prueba de búsqueda con una consulta\n",
    "query = \"¿Qué es tablas?\"\n",
    "buscar_similaridad(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': \"No assistant found with id 'assistant_id'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Ejemplo de uso\u001b[39;00m\n\u001b[0;32m    108\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¿Qué dice el documento sobre inteligencia artificial?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 109\u001b[0m respuesta \u001b[38;5;241m=\u001b[39m \u001b[43mgenerar_respuesta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRespuesta generada:\u001b[39m\u001b[38;5;124m\"\u001b[39m, respuesta)\n",
      "Cell \u001b[1;32mIn[28], line 103\u001b[0m, in \u001b[0;36mgenerar_respuesta\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m    100\u001b[0m thread_id \u001b[38;5;241m=\u001b[39m thread\u001b[38;5;241m.\u001b[39mid  \u001b[38;5;66;03m# Accede al ID del hilo correctamente\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Enviar la consulta al asistente\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m assistant_response \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenai_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBasado en los siguientes documentos, por favor, responde a la consulta: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquery\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcontexto\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m assistant_response\n",
      "Cell \u001b[1;32mIn[28], line 55\u001b[0m, in \u001b[0;36mprocess_data\u001b[1;34m(openai_client, assistant_id, thread_id, message)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mEnvía un mensaje a un asistente de OpenAI y procesa su respuesta.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m openai_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     50\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread_id,\n\u001b[0;32m     51\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m     content\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[0;32m     53\u001b[0m )\n\u001b[1;32m---> 55\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mopenai_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massistant_id\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m run_status \u001b[38;5;241m=\u001b[39m openai_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mruns\u001b[38;5;241m.\u001b[39mretrieve(\n\u001b[0;32m     61\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread_id,\n\u001b[0;32m     62\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\almaz\\.conda\\envs\\prueba_rag_tailor\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\almaz\\.conda\\envs\\prueba_rag_tailor\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\runs.py:567\u001b[0m, in \u001b[0;36mRuns.create\u001b[1;34m(self, thread_id, assistant_id, include, additional_instructions, additional_messages, instructions, max_completion_tokens, max_prompt_tokens, metadata, model, parallel_tool_calls, reasoning_effort, response_format, stream, temperature, tool_choice, tools, top_p, truncation_strategy, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `thread_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    566\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m--> 567\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/threads/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthread_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/runs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_instructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_prompt_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_prompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncation_strategy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAssistantStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\almaz\\.conda\\envs\\prueba_rag_tailor\\Lib\\site-packages\\openai\\_base_client.py:1290\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1278\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1285\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1286\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1287\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1288\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1289\u001b[0m     )\n\u001b[1;32m-> 1290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\almaz\\.conda\\envs\\prueba_rag_tailor\\Lib\\site-packages\\openai\\_base_client.py:967\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\almaz\\.conda\\envs\\prueba_rag_tailor\\Lib\\site-packages\\openai\\_base_client.py:1071\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1070\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1074\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1075\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1080\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': \"No assistant found with id 'assistant_id'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Cargar las variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la clave de API de OpenAI desde las variables de entorno\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Cargar el modelo preentrenado para embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Cargar el índice FAISS previamente guardado\n",
    "index = faiss.read_index(\"mi_indice.index\")\n",
    "\n",
    "# Leer los documentos originales desde el archivo\n",
    "with open('../data/cooked/texto_extraido.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Función para buscar documentos relevantes en FAISS\n",
    "def buscar_documentos(query, k=5):\n",
    "    # Obtener el embedding para la consulta utilizando el modelo\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Buscar en el índice de FAISS los documentos más cercanos\n",
    "    D, I = index.search(query_embedding, k)\n",
    "\n",
    "    # Recuperar los textos de los documentos más cercanos\n",
    "    documents = [lines[i] for i in I[0]]\n",
    "    return documents\n",
    "\n",
    "# Función para crear un hilo de conversación en OpenAI\n",
    "def create_thread(openai_client):\n",
    "    \"\"\"\n",
    "    Crea un nuevo hilo de conversación en OpenAI.\n",
    "    \"\"\"\n",
    "    return openai_client.beta.threads.create()\n",
    "\n",
    "# Función para enviar un mensaje a OpenAI y obtener la respuesta\n",
    "def process_data(openai_client, assistant_id, thread_id, message):\n",
    "    \"\"\"\n",
    "    Envía un mensaje a un asistente de OpenAI y procesa su respuesta.\n",
    "    \"\"\"\n",
    "    openai_client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=message,\n",
    "    )\n",
    "\n",
    "    run = openai_client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "\n",
    "    run_status = openai_client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        run_status = openai_client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if run_status.status == \"completed\":\n",
    "            break\n",
    "        elif run_status.status == \"failed\":\n",
    "            print(\"Error, no se encontró una respuesta del asistente.\")\n",
    "            return \"No se encontró una respuesta del asistente.\"\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "\n",
    "    response_messages = openai_client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    \n",
    "    assistant_response = None\n",
    "    for message in response_messages.data:\n",
    "            assistant_response = \"\\n\".join([block.text.value for block in message.content])\n",
    "            break\n",
    "\n",
    "    return assistant_response\n",
    "\n",
    "# Función para generar una respuesta utilizando los documentos recuperados\n",
    "def generar_respuesta(query):\n",
    "    # Obtener documentos relevantes de FAISS\n",
    "    documents = buscar_documentos(query)\n",
    "    \n",
    "    # Crear el contexto para el asistente, concatenando los documentos relevantes\n",
    "    contexto = \"\\n\".join(documents)\n",
    "\n",
    "    # Inicializa el cliente de OpenAI\n",
    "    openai_client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "    # Crear el hilo\n",
    "    thread = create_thread(openai_client)\n",
    "    thread_id = thread.id  # Accede al ID del hilo correctamente\n",
    "\n",
    "    # Enviar la consulta al asistente\n",
    "    assistant_response = process_data(openai_client, assistant_id=\"asst_lahRwaFfzCaBYGUe3wuK9qT4\", thread_id=thread_id, message=f\"Basado en los siguientes documentos, por favor, responde a la consulta: '{query}'\\n\\n{contexto}\")\n",
    "\n",
    "    return assistant_response\n",
    "\n",
    "# Ejemplo de uso\n",
    "query = \"¿Qué dice el documento sobre inteligencia artificial?\"\n",
    "respuesta = generar_respuesta(query)\n",
    "print(\"Respuesta generada:\", respuesta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'Chat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m consulta \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m¿Cuál es el propósito del sistema de búsqueda?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Generar respuesta usando el sistema\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m respuesta \u001b[38;5;241m=\u001b[39m \u001b[43mgenerar_respuesta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconsulta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRespuesta generada:\u001b[39m\u001b[38;5;124m\"\u001b[39m, respuesta)\n",
      "Cell \u001b[1;32mIn[23], line 45\u001b[0m, in \u001b[0;36mgenerar_respuesta\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     42\u001b[0m contexto \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(documents)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Realizar la consulta a GPT-4 usando la nueva interfaz de API\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChat\u001b[49m\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     46\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Usamos GPT-4\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     48\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEres un asistente útil.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m     49\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasado en los siguientes documentos, por favor, responde a la consulta: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcontexto\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     50\u001b[0m     ]\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Obtener la respuesta generada\u001b[39;00m\n\u001b[0;32m     54\u001b[0m respuesta \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'openai' has no attribute 'Chat'"
     ]
    }
   ],
   "source": [
    "# Ejemplo de consulta\n",
    "consulta = \"¿Cuál es el propósito del sistema de búsqueda?\"\n",
    "\n",
    "# Generar respuesta usando el sistema\n",
    "respuesta = generar_respuesta(consulta)\n",
    "\n",
    "print(\"Respuesta generada:\", respuesta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prueba_rag_tailor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
