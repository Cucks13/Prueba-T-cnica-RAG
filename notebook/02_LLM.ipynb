{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integración con LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Cargar las variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Obtener la clave de API de OpenAI desde las variables de entorno\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Cargar el modelo preentrenado para embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Cargar el índice FAISS previamente guardado\n",
    "index = faiss.read_index(\"mi_indice.index\")\n",
    "\n",
    "# Leer los documentos originales desde el archivo\n",
    "with open('../data/cooked/texto_extraido.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Función para buscar documentos relevantes en FAISS\n",
    "def buscar_documentos(query, k=5):\n",
    "    # Obtener el embedding para la consulta utilizando el modelo\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Buscar en el índice de FAISS los documentos más cercanos\n",
    "    D, I = index.search(query_embedding, k)\n",
    "\n",
    "    # Recuperar los textos de los documentos más cercanos\n",
    "    documents = [lines[i] for i in I[0]]\n",
    "    return documents\n",
    "\n",
    "# Función para crear un hilo de conversación en OpenAI\n",
    "def create_thread(openai_client):\n",
    "    \"\"\"\n",
    "    Crea un nuevo hilo de conversación en OpenAI.\n",
    "    \"\"\"\n",
    "    return openai_client.beta.threads.create()\n",
    "\n",
    "# Función para enviar un mensaje a OpenAI y obtener la respuesta\n",
    "def process_data(openai_client, assistant_id, thread_id, message):\n",
    "    \"\"\"\n",
    "    Envía un mensaje a un asistente de OpenAI y procesa su respuesta.\n",
    "    \"\"\"\n",
    "    openai_client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=message,\n",
    "    )\n",
    "\n",
    "    run = openai_client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id\n",
    "    )\n",
    "\n",
    "    run_status = openai_client.beta.threads.runs.retrieve(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run.id\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        run_status = openai_client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "        if run_status.status == \"completed\":\n",
    "            break\n",
    "        elif run_status.status == \"failed\":\n",
    "            print(\"Error, no se encontró una respuesta del asistente.\")\n",
    "            return \"No se encontró una respuesta del asistente.\"\n",
    "        else:\n",
    "            time.sleep(3)\n",
    "\n",
    "    response_messages = openai_client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    \n",
    "    assistant_response = None\n",
    "    for message in response_messages.data:\n",
    "            assistant_response = \"\\n\".join([block.text.value for block in message.content])\n",
    "            break\n",
    "\n",
    "    return assistant_response\n",
    "\n",
    "# Función para generar una respuesta utilizando los documentos recuperados\n",
    "def generar_respuesta(query):\n",
    "    # Obtener documentos relevantes de FAISS\n",
    "    documents = buscar_documentos(query)\n",
    "    \n",
    "    # Crear el contexto para el asistente, concatenando los documentos relevantes\n",
    "    contexto = \"\\n\".join(documents)\n",
    "\n",
    "    # Inicializa el cliente de OpenAI\n",
    "    openai_client = openai.OpenAI(api_key=openai.api_key)\n",
    "\n",
    "    # Crear el hilo\n",
    "    thread = create_thread(openai_client)\n",
    "    thread_id = thread.id  # Accede al ID del hilo correctamente\n",
    "\n",
    "    # Enviar la consulta al asistente\n",
    "    assistant_response = process_data(openai_client, assistant_id=\"asst_lahRwaFfzCaBYGUe3wuK9qT4\", thread_id=thread_id, message=f\"Basado en los siguientes documentos, por favor, responde a la consulta: '{query}'\\n\\n{contexto}\")\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Creo que he ahogado a mi contringante, como lo puedo saber\"\n",
    "respuesta = generar_respuesta(query)\n",
    "print(\"Respuesta generada:\", respuesta)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
